# 增强版PDF处理流水线

这是一个改进的PDF到语料库转换流水线，相比于原始实现，提供了更高的准确性、更强大的错误处理和增强的功能。

## 特性

- **多种提取方法**: 使用多种PDF提取库并带有备用机制，即使一种方法失败也能确保成功提取文本。
- **智能文本清理**: 先进的文本清理功能，移除页眉、页脚、页码和版权信息，同时保留重要内容。
- **智能文档分段**: 智能分割文档，保持上下文并允许块之间重叠。
- **语义去重**: 移除语义相似的内容，避免训练语料库中的冗余。
- **灵活输出格式**: 同时支持JSONL和平本文本输出格式。
- **进度跟踪**: 提供处理结果的详细统计信息。
- **错误恢复**: 即使某些文件处理失败，也会继续处理其他文件。

## 安装

首先，安装所需的依赖项：

```bash
pip install -r requirements.txt
```

注意：一些高级功能如`unstructured`可能需要额外的依赖项和设置。

## 使用方法

从输入目录处理PDF到输出目录：

```bash
python main.py --input /path/to/input/pdfs --output /path/to/output/directory
```

附加选项：
- `--chunk-size`: 文本块的最大大小 (默认: 1000)
- `--overlap`: 块之间的重叠量 (默认: 100)
- `--threshold`: 去重的相似度阈值 (默认: 0.9)
- `--format`: 输出格式 ('jsonl' 或 'txt', 默认: 'jsonl')

示例：
```bash
python main.py -i ./my_pdfs/ -o ./corpus_output/ --chunk-size 2000 --format jsonl
```

## 架构

该流水线由以下组件组成：

1. **EnhancedPDFProcessor**: 处理所有任务的核心类
2. **文本提取**: PDF文本提取的多种备用方法
3. **文本清理**: 移除不需要的元素，同时保持内容质量
4. **文档分段**: 智能地将文档分割成适当的块
5. **语义去重**: 识别并删除冗余内容
6. **输出生成**: 根据偏好创建JSONL或文本文件

## 使用的库

- `pdfplumber`: 用于从PDF精确提取文本
- `PyMuPDF`: 高性能PDF处理
- `unstructured`: 具有布局保留的高级文档解析
- `sentence-transformers`: 语义相似度计算
- `loguru`: 结构化日志记录
- `tqdm`: 进度条